{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import string\n",
    "import os\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "\n",
    "# keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dropout, Flatten, Dense, BatchNormalization, LSTM, Embedding, Bidirectional, GRU\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text generation with LSTM experiments\n",
    "\n",
    "To sample from a varying stochastic distribution let's create a reweight distribution function that uses \"temperature\" to push the entropy either up or down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600901\n"
     ]
    }
   ],
   "source": [
    "path = keras.utils.get_file('nietzsche.txt', origin = 'https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "\n",
    "text = open(path).read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create overlapping sequences (sliding windows) of sequences of characters. We get new sequences every 3 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of sequences: 200281\n",
      "# of unique chars: 59\n",
      "vectorizing sequences..\n"
     ]
    }
   ],
   "source": [
    "maxlen = 60 #size of sequence\n",
    "step = 3 #we get a new sequence every 3 characters\n",
    "\n",
    "sentences = [] #this will hold the sequences that we extract\n",
    "next_chars = [] #this will hold the targets - the 'correct' characters that we are going to train the model on\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "    \n",
    "print('# of sequences:', len(sentences))\n",
    "\n",
    "chars = sorted(list(set(text))) # all the unique characters in the text since this is the output of softmax layer\n",
    "print(\"# of unique chars:\", len(chars))\n",
    "\n",
    "char_indices = dict((char, chars.index(char)) for char in chars) #get key-value maps for characters and index\n",
    "\n",
    "print(\"vectorizing sequences..\")\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype = np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype = np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False,  True, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200281, 60, 59)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a single 1 layer LSTM model. However, I initiated it with the Keras functional API instead of the normal sequential adding models style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 60, 59)            0         \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 128)               96256     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 59)                7611      \n",
      "=================================================================\n",
      "Total params: 103,867\n",
      "Trainable params: 103,867\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, Input\n",
    "from keras.models import Model\n",
    "\n",
    "input_tensor = Input(shape = (x.shape[1], x.shape[2]))\n",
    "lstm1 = layers.LSTM(128, activation = 'relu')(input_tensor)\n",
    "output_tensor = layers.Dense(len(chars), activation = 'softmax')(lstm1)\n",
    "\n",
    "model = Model(input_tensor, output_tensor)\n",
    "model.summary()\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now after we train the model and inputting some seeding text we can generate new text by following a few steps in a loop:\n",
    "\n",
    "1. draw from a probability distribution for the next character given the seed text and the already generated text.\n",
    "2. reweigh the distribution to a certain temperatue \n",
    "3. sample the next character stochastically with the new distribution\n",
    "4. add the new character to the sequence and repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first we define a function to reweigh the distribution\n",
    "def reweight_distribtution(original_dist, temperature = 0.5):\n",
    "    distribution = np.log(original_dist) / temperature\n",
    "    distribution = np.exp(distribution)\n",
    "    return distribution / np.sum(distribution)\n",
    "\n",
    "#and a function to sample the next character given the prediction of the model\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    \n",
    "    return np.argmax(probas)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set upt he training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 240s 1ms/step - loss: 13.6625\n",
      " --- Generating with seed: ---begin---uffering--know ye not that it is only this\n",
      "discipline that h---end---\n",
      "------ temperature for this epoch: 0.2\n",
      "uffering--know ye not that it is only this\n",
      "discipline that h                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laurens\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                    ------ temperature for this epoch: 0.5\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ------ temperature for this epoch: 1.0\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ------ temperature for this epoch: 1.2\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                            epoch 2\n",
      "Epoch 1/1\n",
      "111232/200281 [===============>..............] - ETA: 1:53 - loss: 13.6695"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 60):\n",
    "    print('epoch', epoch)\n",
    "    model.fit(x, y, batch_size = 128, epochs = 1) #fits model for 1 iteration\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen] #finds a random part of the text as a seed for the generator\n",
    "    print(\" --- Generating with seed: ---begin---\" + generated_text + \"---end---\")\n",
    "    \n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('------ temperature for this epoch:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "        \n",
    "        for i in range(400): #this part generates 400 characters with as start the seed-text\n",
    "            sampled = np.zeros((1, maxlen, len(chars))) \n",
    "            for t, char in enumerate(generated_text): #here we one-hot encode the already generated characters\n",
    "                sampled[0, t, char_indices[char]] = 1\n",
    "                \n",
    "            preds = model.predict(sampled, verbose = 0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "            \n",
    "            generated_text  += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "            \n",
    "            sys.stdout.write(next_char)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                                                           '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
