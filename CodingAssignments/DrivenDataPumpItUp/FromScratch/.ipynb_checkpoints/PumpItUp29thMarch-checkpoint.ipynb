{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Include required libs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train_and_test_data():\n",
    "    train_features=pd.read_csv('TrainingSetValues.csv',parse_dates=True)\n",
    "    train_labels=pd.read_csv('TrainingSetLabels.csv')\n",
    "    to_predict_features=pd.read_csv('TestSetValues.csv',parse_dates=True)\n",
    "    \n",
    "    # merge training features and labels\n",
    "    #training_data = pd.merge(train_features, train_labels, how='inner', on=['id'])\n",
    "    \n",
    "    return train_features, train_labels, to_predict_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_training_data, df_training_labels, df_topredict_data = load_train_and_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert string labels to numerics\n",
    "#label_map = {\"functional\": 1, \"functional needs repair\": 2, \"non functional\": 3}\n",
    "#df_training_data['status_group_num']= df_training_data['status_group'].map(label_map).astype(int)\n",
    "\n",
    "# do sanity check\n",
    "#df_training_data[['id', 'amount_tsh', 'status_group', 'status_group_num']].head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the training labels into a df\n",
    "#df_training_labels_str = df_training_data['status_group']\n",
    "#df_training_labels_num = np.array(df_training_data['status_group_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop the training labels from the training set\n",
    "#df_training_data= df_training_data.drop('status_group', axis = 1)\n",
    "#df_training_data= df_training_data.drop('status_group_num', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Brief Stats of each column\n",
      "*****************************************\n",
      "                 id     amount_tsh    gps_height     longitude      latitude  \\\n",
      "count  59400.000000   59400.000000  59400.000000  59400.000000  5.940000e+04   \n",
      "mean   37115.131768     317.650385    668.297239     34.077427 -5.706033e+00   \n",
      "std    21453.128371    2997.574558    693.116350      6.567432  2.946019e+00   \n",
      "min        0.000000       0.000000    -90.000000      0.000000 -1.164944e+01   \n",
      "25%    18519.750000       0.000000      0.000000     33.090347 -8.540621e+00   \n",
      "50%    37061.500000       0.000000    369.000000     34.908743 -5.021597e+00   \n",
      "75%    55656.500000      20.000000   1319.250000     37.178387 -3.326156e+00   \n",
      "max    74247.000000  350000.000000   2770.000000     40.345193 -2.000000e-08   \n",
      "\n",
      "        num_private   region_code  district_code    population  \\\n",
      "count  59400.000000  59400.000000   59400.000000  59400.000000   \n",
      "mean       0.474141     15.297003       5.629747    179.909983   \n",
      "std       12.236230     17.587406       9.633649    471.482176   \n",
      "min        0.000000      1.000000       0.000000      0.000000   \n",
      "25%        0.000000      5.000000       2.000000      0.000000   \n",
      "50%        0.000000     12.000000       3.000000     25.000000   \n",
      "75%        0.000000     17.000000       5.000000    215.000000   \n",
      "max     1776.000000     99.000000      80.000000  30500.000000   \n",
      "\n",
      "       construction_year  \n",
      "count       59400.000000  \n",
      "mean         1300.652475  \n",
      "std           951.620547  \n",
      "min             0.000000  \n",
      "25%             0.000000  \n",
      "50%          1986.000000  \n",
      "75%          2004.000000  \n",
      "max          2013.000000  \n",
      "\n",
      "*****************************************\n",
      "number of nonzeros in each column\n",
      "*****************************************\n",
      "id                       59399\n",
      "amount_tsh               17761\n",
      "date_recorded            59400\n",
      "funder                   59400\n",
      "gps_height               38962\n",
      "installer                59400\n",
      "longitude                57588\n",
      "latitude                 59400\n",
      "wpt_name                 59400\n",
      "num_private                757\n",
      "basin                    59400\n",
      "subvillage               59400\n",
      "region                   59400\n",
      "region_code              59400\n",
      "district_code            59377\n",
      "lga                      59400\n",
      "ward                     59400\n",
      "population               38019\n",
      "public_meeting           54345\n",
      "recorded_by              59400\n",
      "scheme_management        59400\n",
      "scheme_name              59400\n",
      "permit                   41908\n",
      "construction_year        38691\n",
      "extraction_type          59400\n",
      "extraction_type_group    59400\n",
      "extraction_type_class    59400\n",
      "management               59400\n",
      "management_group         59400\n",
      "payment                  59400\n",
      "payment_type             59400\n",
      "water_quality            59400\n",
      "quality_group            59400\n",
      "quantity                 59400\n",
      "quantity_group           59400\n",
      "source                   59400\n",
      "source_type              59400\n",
      "source_class             59400\n",
      "waterpoint_type          59400\n",
      "waterpoint_type_group    59400\n",
      "dtype: int64\n",
      "\n",
      "*****************************************\n",
      "no. of nulls in each column\n",
      "*****************************************\n",
      "id                           0\n",
      "amount_tsh                   0\n",
      "date_recorded                0\n",
      "funder                    3635\n",
      "gps_height                   0\n",
      "installer                 3655\n",
      "longitude                    0\n",
      "latitude                     0\n",
      "wpt_name                     0\n",
      "num_private                  0\n",
      "basin                        0\n",
      "subvillage                 371\n",
      "region                       0\n",
      "region_code                  0\n",
      "district_code                0\n",
      "lga                          0\n",
      "ward                         0\n",
      "population                   0\n",
      "public_meeting            3334\n",
      "recorded_by                  0\n",
      "scheme_management         3877\n",
      "scheme_name              28166\n",
      "permit                    3056\n",
      "construction_year            0\n",
      "extraction_type              0\n",
      "extraction_type_group        0\n",
      "extraction_type_class        0\n",
      "management                   0\n",
      "management_group             0\n",
      "payment                      0\n",
      "payment_type                 0\n",
      "water_quality                0\n",
      "quality_group                0\n",
      "quantity                     0\n",
      "quantity_group               0\n",
      "source                       0\n",
      "source_type                  0\n",
      "source_class                 0\n",
      "waterpoint_type              0\n",
      "waterpoint_type_group        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"*****************************************\\nBrief Stats of each column\\n*****************************************\")\n",
    "print(df_training_data.describe())\n",
    "\n",
    "#getting number of nonzeros in each column\n",
    "print(\"\\n*****************************************\\nnumber of nonzeros in each column\\n*****************************************\")\n",
    "print(df_training_data.astype(bool).sum(axis=0))\n",
    "\n",
    "# getting no. of nulls in each column\n",
    "print(\"\\n*****************************************\\nno. of nulls in each column\\n*****************************************\")\n",
    "print(df_training_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute median values for 0 amount_tsh\n",
    "def impute_missing_amount_tsh(df):\n",
    "    df.amount_tsh[df.amount_tsh <= 0] = np.median(df.amount_tsh[df.amount_tsh > 0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute median values for 0 gps height\n",
    "def impute_missing_gps_height(df):\n",
    "    df.gps_height[df.gps_height <= 0] = np.median(df.gps_height[df.gps_height > 0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute median values for 0 population\n",
    "def impute_missing_population(df):\n",
    "    df.population[df.population <= 0] = np.median(df.population[df.population > 0])\n",
    "    return df\n",
    "\n",
    "def impute_missing_population1(df):\n",
    "    df.population[df.population <= 0] = \"NA\"\n",
    "    df.population[df.population >= 2 & df.population <=40] = \"A\"\n",
    "    df.population[df.population >= 41 & df.population <=67] = \"B\"\n",
    "    df.population[df.population >= 68 & df.population <=99] = \"C\"\n",
    "    df.population[df.population >= 100 & df.population <=131] = \"D\"\n",
    "    df.population[df.population >= 132 & df.population <=175] = \"E\"\n",
    "    df.population[df.population >= 176 & df.population <=219] = \"F\"\n",
    "    df.population[df.population >= 220 & df.population <=259] = \"G\"\n",
    "    df.population[df.population >= 260 & df.population <=349] = \"H\"\n",
    "    df.population[df.population >= 350 & df.population <=448] = \"I\"\n",
    "    df.population[df.population >= 449 & df.population <=598] = \"L\"\n",
    "    df.population[df.population >= 599 & df.population <=1290] = \"M\"\n",
    "    df.population[df.population >= 1300] = \"N\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute median values for construction year\n",
    "def impute_missing_construction_year(df):\n",
    "    df.construction_year[df.construction_year <= 0] = np.median(df.construction_year[df.construction_year > 0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute missing booleans with false and convert each value to float or integer\n",
    "def impute_missing_booleans(df, colname):\n",
    "    df[colname].fillna(False, inplace = True)\n",
    "    df[colname] = df[colname].apply(lambda x: float(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dates(X_train, X_test):\n",
    "    \"\"\"\n",
    "    date_recorded: this might be a useful variable for this analysis, although the year itself would be useless \n",
    "    in a practical scenario moving into the future. \n",
    "    We will convert this column into a datetime, and we will also \n",
    "    create 'year_recorded' and 'month_recorded' columns just in case those levels prove to be useful. \n",
    "    A visual inspection of both casts significant doubt on that possibility, but we'll proceed for now. \n",
    "    We will delete date_recorded itself, since random forest cannot accept datetime\n",
    "    \"\"\"\n",
    "    for i in [X_train, X_test]:\n",
    "        i['date_recorded'] = pd.to_datetime(i['date_recorded'])\n",
    "        i['year_recorded'] = i['date_recorded'].apply(lambda x: x.year)\n",
    "        i['month_recorded'] = i['date_recorded'].apply(lambda x: x.month)\n",
    "        i['date_recorded'] = (pd.to_datetime(i['date_recorded'])).apply(lambda x: x.toordinal())\n",
    "    return X_train, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dates2(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Turn year_recorded and month_recorded into dummy variables\n",
    "    \"\"\"\n",
    "    for z in ['month_recorded', 'year_recorded']:\n",
    "        X_train[z] = X_train[z].apply(lambda x: str(x))\n",
    "        X_test[z] = X_test[z].apply(lambda x: str(x))\n",
    "        good_cols = [z+'_'+i for i in X_train[z].unique() if i in X_test[z].unique()]\n",
    "        X_train = pd.concat((X_train, pd.get_dummies(X_train[z], prefix = z)[good_cols]), axis = 1)\n",
    "        X_test = pd.concat((X_test, pd.get_dummies(X_test[z], prefix = z)[good_cols]), axis = 1)\n",
    "        del X_test[z]\n",
    "        del X_train[z]\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def locs(X_train, X_test):\n",
    "    \"\"\"\n",
    "    fill in the nulls for ['longitude', 'latitude', 'gps_height', 'population'] by using means from \n",
    "    ['subvillage', 'district_code', 'basin'], and lastly the overall mean\n",
    "    \"\"\"\n",
    "    trans = ['longitude', 'latitude', 'gps_height', 'population']\n",
    "    for i in [X_train, X_test]:\n",
    "        i.loc[i.longitude == 0, 'latitude'] = 0\n",
    "    for z in trans:\n",
    "        for i in [X_train, X_test]:\n",
    "            i[z].replace(0., np.NaN, inplace = True)\n",
    "            i[z].replace(1., np.NaN, inplace = True)\n",
    "        \n",
    "        for j in ['subvillage', 'district_code', 'basin']:\n",
    "        \n",
    "            X_train['mean'] = X_train.groupby([j])[z].transform('mean')\n",
    "            X_train[z] = X_train[z].fillna(X_train['mean'])\n",
    "            o = X_train.groupby([j])[z].mean()\n",
    "            fill = pd.merge(X_test, pd.DataFrame(o), left_on=[j], right_index=True, how='left').iloc[:,-1]\n",
    "            X_test[z] = X_test[z].fillna(fill)\n",
    "        \n",
    "        X_train[z] = X_train[z].fillna(X_train[z].mean())\n",
    "        X_test[z] = X_test[z].fillna(X_train[z].mean())\n",
    "        del X_train['mean']\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to drop from a dataframe\n",
    "def drop_columns(df, cols_to_drop):\n",
    "    for col in cols_to_drop:\n",
    "        del df[col]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(p):\n",
    "    return 1-(p**2 + (1-p)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def small_n2(X_train, X_test):\n",
    "    cols = [i for i in X_train.columns if type(X_train[i].iloc[0]) == str]\n",
    "    X_train[cols] = X_train[cols].where(X_train[cols].apply(lambda x: x.map(x.value_counts())) > 100, \"other\")\n",
    "    for column in cols:\n",
    "        for i in X_test[column].unique():\n",
    "            if i not in X_train[column].unique():\n",
    "                X_test[column].replace(i, 'other', inplace=True)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lda(X_train, X_test, y_train, cols=['population', 'gps_height', 'latitude', 'longitude']):\n",
    "    sc = StandardScaler()\n",
    "    X_train_std = sc.fit_transform(X_train[cols])\n",
    "    X_test_std = sc.transform(X_test[cols])\n",
    "    lda = LDA(n_components=None)\n",
    "    X_train_lda = lda.fit_transform(X_train_std, y_train.values.ravel())\n",
    "    X_test_lda = lda.transform(X_test_std)\n",
    "    X_train = pd.concat((pd.DataFrame(X_train_lda), X_train), axis=1)\n",
    "    X_test = pd.concat((pd.DataFrame(X_test_lda), X_test), axis=1)\n",
    "    for i in cols:\n",
    "        del X_train[i]\n",
    "        del X_test[i]\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def one_hot_encode(X_train, X_test):\n",
    "#    columns = [i for i in X_train.columns if type(X_train[i].iloc[0]) == str]\n",
    "#    for column in columns:\n",
    "#        X_train[column].fillna('NULL', inplace = True)\n",
    "#        good_cols = [column+'_'+i for i in X_train[column].unique() if i in X_test[column].unique()]\n",
    "#        X_train = pd.concat((X_train, pd.get_dummies(X_train[column], prefix = column)[good_cols]), axis = 1)\n",
    "#        X_test = pd.concat((X_test, pd.get_dummies(X_test[column], prefix = column)[good_cols]), axis = 1)\n",
    "#        del X_train[column]\n",
    "#        del X_test[column]\n",
    "#    return X_train, X_test\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(df_train, df_test):\n",
    "    columns = [i for i in df_train.columns if type(df_train[i].iloc[0]) == str]\n",
    "    for column in columns:\n",
    "        df_train[column].fillna('NULL', inplace = True)\n",
    "        ohe_cols = [column+'_'+i for i in df_train[column].unique() if i in df_test[column].unique()]\n",
    "        df_train = pd.concat((df_train, pd.get_dummies(df_train[column], prefix = column)[ohe_cols]), axis = 1)\n",
    "        df_test = pd.concat((df_test, pd.get_dummies(df_test[column], prefix = column)[ohe_cols]), axis = 1)\n",
    "        del df_train[column]\n",
    "        del df_test[column]\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode1(df):\n",
    "    columns = [x for x in df.columns if type(df[x].iloc[0]) == str]\n",
    "    for column in columns:\n",
    "        df[column].fillna('NULL', inplace = True)\n",
    "        ohe_cols = [column + '_' + x for x in df[column].unique() if x in df[column].unique()]\n",
    "        df = pd.concat((df, pd.get_dummies(df[column], prefix = column)[ohe_cols]), axis = 1)\n",
    "        del df[column]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze_unique_values_for_column(df, colname):\n",
    "    unique_col_vals = df[colname].unique()\n",
    "    tmp_str = \"Unique \" + colname + \"s:\"\n",
    "    print(\"****************************\")\n",
    "    print(tmp_str, unique_col_vals.size)\n",
    "    print(\"****************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************\n",
      "Unique funders: 1898\n",
      "****************************\n",
      "****************************\n",
      "Unique installers: 2146\n",
      "****************************\n",
      "****************************\n",
      "Unique wpt_names: 37400\n",
      "****************************\n",
      "****************************\n",
      "Unique basins: 9\n",
      "****************************\n",
      "****************************\n",
      "Unique subvillages: 19288\n",
      "****************************\n",
      "****************************\n",
      "Unique regions: 21\n",
      "****************************\n",
      "****************************\n",
      "Unique region_codes: 27\n",
      "****************************\n",
      "****************************\n",
      "Unique district_codes: 20\n",
      "****************************\n",
      "****************************\n",
      "Unique lgas: 125\n",
      "****************************\n",
      "****************************\n",
      "Unique wards: 2092\n",
      "****************************\n",
      "****************************\n",
      "Unique recorded_bys: 1\n",
      "****************************\n",
      "****************************\n",
      "Unique scheme_managements: 13\n",
      "****************************\n",
      "****************************\n",
      "Unique scheme_names: 2697\n",
      "****************************\n",
      "****************************\n",
      "Unique extraction_types: 18\n",
      "****************************\n",
      "****************************\n",
      "Unique extraction_type_groups: 13\n",
      "****************************\n",
      "****************************\n",
      "Unique extraction_type_classs: 7\n",
      "****************************\n",
      "****************************\n",
      "Unique managements: 12\n",
      "****************************\n",
      "****************************\n",
      "Unique management_groups: 5\n",
      "****************************\n",
      "****************************\n",
      "Unique management_groups: 5\n",
      "****************************\n",
      "****************************\n",
      "Unique payments: 7\n",
      "****************************\n",
      "****************************\n",
      "Unique payment_types: 7\n",
      "****************************\n",
      "****************************\n",
      "Unique management_groups: 5\n",
      "****************************\n",
      "****************************\n",
      "Unique water_qualitys: 8\n",
      "****************************\n",
      "****************************\n",
      "Unique quality_groups: 6\n",
      "****************************\n",
      "****************************\n",
      "Unique quantitys: 5\n",
      "****************************\n",
      "****************************\n",
      "Unique quantity_groups: 5\n",
      "****************************\n",
      "****************************\n",
      "Unique sources: 10\n",
      "****************************\n",
      "****************************\n",
      "Unique source_types: 7\n",
      "****************************\n",
      "****************************\n",
      "Unique source_classs: 3\n",
      "****************************\n",
      "****************************\n",
      "Unique source_classs: 3\n",
      "****************************\n",
      "****************************\n",
      "Unique waterpoint_types: 7\n",
      "****************************\n",
      "****************************\n",
      "Unique waterpoint_type_groups: 6\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "analyze_unique_values_for_column(df_training_data, \"funder\")\n",
    "analyze_unique_values_for_column(df_training_data, \"installer\")\n",
    "analyze_unique_values_for_column(df_training_data, \"wpt_name\")\n",
    "analyze_unique_values_for_column(df_training_data, \"basin\")\n",
    "analyze_unique_values_for_column(df_training_data, \"subvillage\")\n",
    "analyze_unique_values_for_column(df_training_data, \"region\")\n",
    "analyze_unique_values_for_column(df_training_data, \"region_code\")\n",
    "analyze_unique_values_for_column(df_training_data, \"district_code\")\n",
    "analyze_unique_values_for_column(df_training_data, \"lga\")\n",
    "analyze_unique_values_for_column(df_training_data, \"ward\")\n",
    "analyze_unique_values_for_column(df_training_data, \"recorded_by\")\n",
    "analyze_unique_values_for_column(df_training_data, \"scheme_management\")\n",
    "analyze_unique_values_for_column(df_training_data, \"scheme_name\")\n",
    "analyze_unique_values_for_column(df_training_data, \"extraction_type\")\n",
    "analyze_unique_values_for_column(df_training_data, \"extraction_type_group\")\n",
    "analyze_unique_values_for_column(df_training_data, \"extraction_type_class\")\n",
    "analyze_unique_values_for_column(df_training_data, \"management\")\n",
    "analyze_unique_values_for_column(df_training_data, \"management_group\")\n",
    "analyze_unique_values_for_column(df_training_data, \"management_group\")\n",
    "analyze_unique_values_for_column(df_training_data, \"payment\")\n",
    "analyze_unique_values_for_column(df_training_data, \"payment_type\")\n",
    "analyze_unique_values_for_column(df_training_data, \"management_group\")\n",
    "analyze_unique_values_for_column(df_training_data, \"water_quality\")\n",
    "analyze_unique_values_for_column(df_training_data, \"quality_group\")\n",
    "analyze_unique_values_for_column(df_training_data, \"quantity\")\n",
    "analyze_unique_values_for_column(df_training_data, \"quantity_group\")\n",
    "analyze_unique_values_for_column(df_training_data, \"source\")\n",
    "analyze_unique_values_for_column(df_training_data, \"source_type\")\n",
    "analyze_unique_values_for_column(df_training_data, \"source_class\")\n",
    "analyze_unique_values_for_column(df_training_data, \"source_class\")\n",
    "analyze_unique_values_for_column(df_training_data, \"waterpoint_type\")\n",
    "analyze_unique_values_for_column(df_training_data, \"waterpoint_type_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze_in_detail_unique_values_for_column(df, colname):\n",
    "    unique_col_vals = df[colname].unique()\n",
    "    tmp_str = \"Unique \" + colname + \"s:\"\n",
    "    print(\"****************************\")\n",
    "    print(tmp_str, unique_col_vals.size)\n",
    "    print(\"****************************\")\n",
    "    lessthan10 = 0\n",
    "    lessthan20 = 0\n",
    "    lessthan30 = 0\n",
    "    lessthan50 = 0\n",
    "    lessthan100 = 0\n",
    "    for val in unique_col_vals:\n",
    "        cnt = df[df[colname] == val][colname].count()\n",
    "        print(val, cnt) # uncomment this line if you want to see the count of each colname-value\n",
    "        if(cnt < 10):\n",
    "            lessthan10 +=1     \n",
    "            print(val, cnt)\n",
    "        elif(cnt < 20):\n",
    "            lessthan20 +=1\n",
    "        elif(cnt < 30):\n",
    "            lessthan30 +=1\n",
    "        elif(cnt < 50):\n",
    "            lessthan50 +=1\n",
    "\n",
    "    print(\"lessthan50: \", lessthan50 )\n",
    "    print(\"lessthan30: \", lessthan30 )\n",
    "    print(\"lessthan20: \", lessthan20 )\n",
    "    print(\"lessthan10: \", lessthan10 )\n",
    "    print(\"****************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************\n",
      "Unique populations: 1049\n",
      "****************************\n",
      "109 19\n",
      "280 104\n",
      "250 1681\n",
      "58 25\n",
      "0 21381\n",
      "1 7025\n",
      "345 29\n",
      "200 1940\n",
      "35 245\n",
      "50 1139\n",
      "1000 278\n",
      "4 13\n",
      "350 986\n",
      "210 209\n",
      "156 61\n",
      "140 215\n",
      "260 125\n",
      "150 1892\n",
      "180 183\n",
      "70 209\n",
      "100 1146\n",
      "230 388\n",
      "30 626\n",
      "20 462\n",
      "10 163\n",
      "45 205\n",
      "456 21\n",
      "567 5\n",
      "130 264\n",
      "225 52\n",
      "54 19\n",
      "75 289\n",
      "900 70\n",
      "360 222\n",
      "544 1\n",
      "441 1\n",
      "120 916\n",
      "40 552\n",
      "221 9\n",
      "950 64\n",
      "1430 3\n",
      "110 64\n",
      "256 66\n",
      "320 249\n",
      "90 265\n",
      "804 1\n",
      "600 438\n",
      "370 56\n",
      "305 8\n",
      "1600 23\n",
      "400 775\n",
      "590 18\n",
      "450 499\n",
      "80 533\n",
      "560 106\n",
      "2500 56\n",
      "1050 12\n",
      "36 57\n",
      "540 110\n",
      "300 1476\n",
      "12 43\n",
      "632 5\n",
      "245 47\n",
      "32 17\n",
      "59 15\n",
      "25 255\n",
      "500 1009\n",
      "570 22\n",
      "700 192\n",
      "111 1\n",
      "630 54\n",
      "270 72\n",
      "55 116\n",
      "1700 7\n",
      "800 269\n",
      "87 9\n",
      "2530 8\n",
      "86 99\n",
      "96 112\n",
      "240 154\n",
      "203 22\n",
      "215 48\n",
      "98 77\n",
      "160 127\n",
      "1200 168\n",
      "309 4\n",
      "95 44\n",
      "60 706\n",
      "85 70\n",
      "159 8\n",
      "65 175\n",
      "48 22\n",
      "2150 3\n",
      "1013 2\n",
      "220 74\n",
      "1680 1\n",
      "375 11\n",
      "2000 130\n",
      "125 113\n",
      "3226 5\n",
      "253 27\n",
      "88 10\n",
      "820 11\n",
      "133 5\n",
      "650 177\n",
      "163 10\n",
      "430 53\n",
      "290 34\n",
      "2100 17\n",
      "285 17\n",
      "425 11\n",
      "155 22\n",
      "1500 190\n",
      "185 33\n",
      "368 6\n",
      "115 21\n",
      "520 69\n",
      "406 1\n",
      "970 2\n",
      "52 32\n",
      "750 153\n",
      "380 80\n",
      "123 59\n",
      "730 3\n",
      "105 43\n",
      "452 11\n",
      "1320 5\n",
      "14 18\n",
      "261 8\n",
      "82 5\n",
      "550 101\n",
      "393 3\n",
      "348 2\n",
      "89 61\n",
      "412 7\n",
      "530 66\n",
      "386 4\n",
      "278 6\n",
      "212 16\n",
      "340 77\n",
      "568 5\n",
      "418 1\n",
      "56 150\n",
      "516 1\n",
      "6922 30\n",
      "183 11\n",
      "6 19\n",
      "980 14\n",
      "263 14\n",
      "480 52\n",
      "1250 29\n",
      "8 23\n",
      "321 15\n",
      "420 162\n",
      "620 42\n",
      "5153 6\n",
      "2353 1\n",
      "440 7\n",
      "1015 1\n",
      "269 17\n",
      "44 10\n",
      "174 7\n",
      "323 5\n",
      "233 7\n",
      "258 31\n",
      "152 10\n",
      "42 29\n",
      "358 19\n",
      "211 13\n",
      "855 2\n",
      "1020 6\n",
      "15 193\n",
      "69 25\n",
      "145 62\n",
      "22 9\n",
      "246 10\n",
      "99 17\n",
      "137 2\n",
      "124 11\n",
      "680 30\n",
      "740 30\n",
      "333 2\n",
      "1180 1\n",
      "53 59\n",
      "355 10\n",
      "1041 15\n",
      "390 39\n",
      "265 17\n",
      "465 9\n",
      "1632 1\n",
      "1360 1\n",
      "182 11\n",
      "2395 1\n",
      "356 27\n",
      "580 37\n",
      "453 10\n",
      "46 7\n",
      "471 1\n",
      "284 3\n",
      "9 11\n",
      "819 1\n",
      "1506 1\n",
      "68 28\n",
      "132 19\n",
      "369 12\n",
      "235 40\n",
      "144 11\n",
      "591 3\n",
      "103 8\n",
      "335 11\n",
      "875 2\n",
      "812 5\n",
      "195 27\n",
      "5 44\n",
      "315 16\n",
      "685 6\n",
      "548 3\n",
      "554 3\n",
      "860 21\n",
      "83 9\n",
      "2200 6\n",
      "3200 6\n",
      "1070 1\n",
      "415 6\n",
      "455 7\n",
      "850 60\n",
      "1650 7\n",
      "222 3\n",
      "2800 6\n",
      "330 36\n",
      "670 11\n",
      "780 15\n",
      "608 3\n",
      "162 6\n",
      "357 5\n",
      "1570 4\n",
      "231 19\n",
      "135 39\n",
      "114 7\n",
      "531 4\n",
      "57 15\n",
      "234 21\n",
      "101 4\n",
      "170 72\n",
      "1530 4\n",
      "134 11\n",
      "67 7\n",
      "176 9\n",
      "610 12\n",
      "154 14\n",
      "26 11\n",
      "2013 1\n",
      "204 6\n",
      "213 19\n",
      "405 9\n",
      "236 20\n",
      "239 7\n",
      "532 8\n",
      "64 5\n",
      "458 7\n",
      "1140 2\n",
      "153 30\n",
      "4100 1\n",
      "126 30\n",
      "205 35\n",
      "1740 1\n",
      "2300 15\n",
      "749 1\n",
      "190 50\n",
      "1850 4\n",
      "802 3\n",
      "1400 32\n",
      "595 3\n",
      "217 7\n",
      "23 27\n",
      "365 21\n",
      "168 16\n",
      "1009 2\n",
      "139 3\n",
      "97 6\n",
      "2698 1\n",
      "143 15\n",
      "198 11\n",
      "84 12\n",
      "810 5\n",
      "640 12\n",
      "445 15\n",
      "634 4\n",
      "954 2\n",
      "17 6\n",
      "1220 2\n",
      "72 21\n",
      "5030 1\n",
      "720 19\n",
      "579 2\n",
      "295 13\n",
      "341 8\n",
      "563 13\n",
      "310 31\n",
      "76 25\n",
      "1040 1\n",
      "107 3\n",
      "338 5\n",
      "1100 19\n",
      "840 16\n",
      "189 17\n",
      "413 5\n",
      "352 10\n",
      "423 16\n",
      "325 42\n",
      "4005 2\n",
      "679 3\n",
      "1750 4\n",
      "896 3\n",
      "1800 24\n",
      "3500 22\n",
      "710 3\n",
      "61 4\n",
      "385 14\n",
      "362 6\n",
      "3020 2\n",
      "690 7\n",
      "4500 9\n",
      "460 23\n",
      "459 5\n",
      "397 3\n",
      "4000 26\n",
      "157 5\n",
      "206 10\n",
      "475 11\n",
      "346 4\n",
      "268 11\n",
      "186 11\n",
      "164 3\n",
      "1161 1\n",
      "779 1\n",
      "3127 1\n",
      "3000 41\n",
      "354 9\n",
      "38 9\n",
      "542 3\n",
      "656 1\n",
      "897 4\n",
      "181 3\n",
      "259 12\n",
      "890 17\n",
      "769 9\n",
      "63 31\n",
      "759 1\n",
      "94 5\n",
      "7500 3\n",
      "367 10\n",
      "119 2\n",
      "863 4\n",
      "512 5\n",
      "5000 20\n",
      "255 19\n",
      "243 9\n",
      "49 9\n",
      "396 9\n",
      "654 3\n",
      "6000 15\n",
      "102 22\n",
      "254 21\n",
      "374 3\n",
      "1450 10\n",
      "264 9\n",
      "6500 7\n",
      "1520 4\n",
      "1486 1\n",
      "574 1\n",
      "266 11\n",
      "313 3\n",
      "432 8\n",
      "569 7\n",
      "241 20\n",
      "602 1\n",
      "1160 1\n",
      "209 8\n",
      "653 7\n",
      "165 22\n",
      "4900 1\n",
      "2 4\n",
      "1177 1\n",
      "628 1\n",
      "81 2\n",
      "106 6\n",
      "108 21\n",
      "487 3\n",
      "175 51\n",
      "158 5\n",
      "483 3\n",
      "267 4\n",
      "7000 2\n",
      "543 7\n",
      "3110 3\n",
      "219 9\n",
      "603 2\n",
      "1900 7\n",
      "4210 1\n",
      "149 13\n",
      "16 8\n",
      "2445 4\n",
      "271 4\n",
      "142 12\n",
      "251 8\n",
      "1540 4\n",
      "410 25\n",
      "736 1\n",
      "1930 1\n",
      "117 6\n",
      "857 2\n",
      "39 3\n",
      "286 11\n",
      "490 22\n",
      "147 5\n",
      "299 1\n",
      "3981 1\n",
      "66 5\n",
      "302 8\n",
      "960 14\n",
      "502 4\n",
      "128 8\n",
      "956 2\n",
      "298 7\n",
      "188 8\n",
      "510 14\n",
      "29 7\n",
      "146 15\n",
      "830 10\n",
      "324 16\n",
      "1903 2\n",
      "79 13\n",
      "842 1\n",
      "192 8\n",
      "1440 1\n",
      "312 17\n",
      "495 6\n",
      "274 4\n",
      "1226 1\n",
      "616 3\n",
      "825 4\n",
      "513 3\n",
      "1230 14\n",
      "293 1\n",
      "488 8\n",
      "2210 1\n",
      "167 7\n",
      "1300 37\n",
      "660 5\n",
      "5500 2\n",
      "519 1\n",
      "194 3\n",
      "1614 1\n",
      "578 3\n",
      "734 1\n",
      "1280 3\n",
      "499 1\n",
      "238 7\n",
      "478 5\n",
      "2130 2\n",
      "536 6\n",
      "668 3\n",
      "214 21\n",
      "318 2\n",
      "533 1\n",
      "327 3\n",
      "760 9\n",
      "291 4\n",
      "457 5\n",
      "525 8\n",
      "743 2\n",
      "223 7\n",
      "294 3\n",
      "3800 4\n",
      "556 5\n",
      "1237 2\n",
      "224 1\n",
      "1030 4\n",
      "715 1\n",
      "963 2\n",
      "287 3\n",
      "4523 1\n",
      "2700 4\n",
      "317 3\n",
      "1034 1\n",
      "178 8\n",
      "19 3\n",
      "3600 3\n",
      "790 5\n",
      "742 3\n",
      "18 18\n",
      "462 3\n",
      "273 3\n",
      "199 4\n",
      "232 6\n",
      "470 39\n",
      "172 8\n",
      "289 5\n",
      "586 3\n",
      "1550 5\n",
      "770 2\n",
      "249 7\n",
      "442 3\n",
      "1205 2\n",
      "193 2\n",
      "655 5\n",
      "2400 6\n",
      "78 27\n",
      "658 3\n",
      "216 7\n",
      "296 7\n",
      "662 1\n",
      "226 3\n",
      "454 21\n",
      "13 12\n",
      "244 6\n",
      "589 6\n",
      "4550 1\n",
      "435 9\n",
      "528 2\n",
      "5600 3\n",
      "1185 1\n",
      "8000 5\n",
      "306 7\n",
      "561 1\n",
      "596 2\n",
      "703 3\n",
      "2016 1\n",
      "592 2\n",
      "127 4\n",
      "1807 1\n",
      "893 3\n",
      "288 9\n",
      "2129 1\n",
      "558 2\n",
      "4530 2\n",
      "675 3\n",
      "935 2\n",
      "392 1\n",
      "834 2\n",
      "725 1\n",
      "587 2\n",
      "1960 1\n",
      "11 7\n",
      "594 3\n",
      "257 6\n",
      "73 7\n",
      "698 3\n",
      "467 3\n",
      "588 3\n",
      "382 2\n",
      "112 12\n",
      "722 1\n",
      "92 6\n",
      "726 1\n",
      "663 1\n",
      "732 2\n",
      "136 12\n",
      "24 16\n",
      "3072 1\n",
      "1724 1\n",
      "4600 1\n",
      "297 3\n",
      "886 1\n",
      "34 10\n",
      "5200 1\n",
      "74 4\n",
      "438 4\n",
      "151 2\n",
      "856 3\n",
      "853 2\n",
      "275 26\n",
      "8600 1\n",
      "2350 5\n",
      "2385 1\n",
      "1065 1\n",
      "336 4\n",
      "635 1\n",
      "1056 4\n",
      "529 2\n",
      "798 1\n",
      "411 2\n",
      "598 3\n",
      "865 2\n",
      "351 2\n",
      "1860 6\n",
      "3450 1\n",
      "816 4\n",
      "585 2\n",
      "961 3\n",
      "2560 2\n",
      "524 4\n",
      "161 3\n",
      "642 6\n",
      "361 3\n",
      "347 6\n",
      "1234 2\n",
      "314 3\n",
      "665 2\n",
      "1150 2\n",
      "1120 2\n",
      "545 8\n",
      "9865 1\n",
      "461 2\n",
      "177 1\n",
      "748 1\n",
      "1036 1\n",
      "247 5\n",
      "113 10\n",
      "301 4\n",
      "427 2\n",
      "565 2\n",
      "5016 1\n",
      "814 3\n",
      "329 3\n",
      "51 8\n",
      "1502 1\n",
      "252 4\n",
      "1720 3\n",
      "501 1\n",
      "927 1\n",
      "721 2\n",
      "303 4\n",
      "9500 1\n",
      "498 2\n",
      "2620 1\n",
      "1830 3\n",
      "538 1\n",
      "476 3\n",
      "116 3\n",
      "3832 1\n",
      "322 6\n",
      "5400 2\n",
      "276 2\n",
      "6300 1\n",
      "15300 1\n",
      "712 7\n",
      "344 3\n",
      "621 3\n",
      "2813 1\n",
      "207 3\n",
      "447 2\n",
      "2020 1\n",
      "468 1\n",
      "27 5\n",
      "4230 1\n",
      "389 7\n",
      "328 6\n",
      "674 3\n",
      "1950 2\n",
      "874 2\n",
      "196 13\n",
      "208 6\n",
      "4200 2\n",
      "1483 1\n",
      "384 2\n",
      "43 7\n",
      "645 1\n",
      "521 4\n",
      "28 9\n",
      "93 4\n",
      "353 4\n",
      "395 4\n",
      "880 3\n",
      "1193 1\n",
      "678 3\n",
      "1831 1\n",
      "304 4\n",
      "1305 1\n",
      "122 3\n",
      "1436 3\n",
      "283 5\n",
      "1510 2\n",
      "1251 1\n",
      "218 8\n",
      "625 4\n",
      "523 15\n",
      "755 4\n",
      "1968 1\n",
      "227 2\n",
      "433 3\n",
      "714 5\n",
      "71 5\n",
      "537 1\n",
      "572 1\n",
      "121 4\n",
      "1306 1\n",
      "6800 1\n",
      "807 1\n",
      "463 6\n",
      "237 2\n",
      "407 1\n",
      "1685 1\n",
      "2954 1\n",
      "33 9\n",
      "575 1\n",
      "966 1\n",
      "2780 1\n",
      "629 2\n",
      "643 4\n",
      "1890 1\n",
      "8848 1\n",
      "482 2\n",
      "334 2\n",
      "571 1\n",
      "37 4\n",
      "2684 1\n",
      "2630 1\n",
      "672 1\n",
      "964 2\n",
      "930 5\n",
      "1942 1\n",
      "3540 3\n",
      "583 3\n",
      "331 2\n",
      "646 1\n",
      "2314 1\n",
      "1885 1\n",
      "242 7\n",
      "511 2\n",
      "202 4\n",
      "518 3\n",
      "408 1\n",
      "359 4\n",
      "581 4\n",
      "5050 1\n",
      "652 3\n",
      "786 3\n",
      "584 3\n",
      "723 1\n",
      "948 1\n",
      "517 2\n",
      "3 4\n",
      "870 5\n",
      "735 11\n",
      "184 6\n",
      "606 3\n",
      "77 5\n",
      "6330 1\n",
      "566 6\n",
      "326 4\n",
      "489 1\n",
      "281 4\n",
      "2050 2\n",
      "1038 2\n",
      "843 2\n",
      "8500 1\n",
      "7 3\n",
      "701 1\n",
      "104 1\n",
      "1590 1\n",
      "486 3\n",
      "148 10\n",
      "1206 1\n",
      "376 1\n",
      "905 1\n",
      "657 2\n",
      "745 2\n",
      "821 1\n",
      "782 3\n",
      "448 2\n",
      "3050 1\n",
      "272 3\n",
      "1380 1\n",
      "171 1\n",
      "2514 1\n",
      "421 3\n",
      "141 1\n",
      "428 3\n",
      "1432 1\n",
      "1019 1\n",
      "618 2\n",
      "6854 1\n",
      "527 4\n",
      "2652 1\n",
      "823 2\n",
      "5300 1\n",
      "564 2\n",
      "1265 1\n",
      "1840 1\n",
      "815 2\n",
      "41 3\n",
      "201 2\n",
      "3236 1\n",
      "1375 3\n",
      "248 5\n",
      "3982 1\n",
      "444 3\n",
      "4310 3\n",
      "402 1\n",
      "903 1\n",
      "686 2\n",
      "469 2\n",
      "47 4\n",
      "308 3\n",
      "339 1\n",
      "638 2\n",
      "479 1\n",
      "187 2\n",
      "496 4\n",
      "129 3\n",
      "684 3\n",
      "906 2\n",
      "2450 3\n",
      "633 2\n",
      "2807 1\n",
      "503 1\n",
      "364 4\n",
      "535 1\n",
      "292 1\n",
      "793 3\n",
      "869 1\n",
      "882 3\n",
      "332 3\n",
      "1350 3\n",
      "1710 1\n",
      "229 2\n",
      "756 5\n",
      "974 1\n",
      "3014 1\n",
      "746 2\n",
      "3821 1\n",
      "4800 2\n",
      "372 2\n",
      "711 1\n",
      "1630 1\n",
      "169 4\n",
      "2600 3\n",
      "1863 1\n",
      "1745 1\n",
      "437 2\n",
      "1114 1\n",
      "789 1\n",
      "10000 3\n",
      "492 2\n",
      "424 1\n",
      "4145 1\n",
      "30500 1\n",
      "431 1\n",
      "2670 1\n",
      "118 3\n",
      "1534 2\n",
      "1839 1\n",
      "3355 1\n",
      "1274 1\n",
      "1560 4\n",
      "228 2\n",
      "9000 3\n",
      "868 1\n",
      "2511 1\n",
      "887 1\n",
      "485 11\n",
      "805 2\n",
      "4520 1\n",
      "1018 2\n",
      "504 1\n",
      "62 4\n",
      "3560 1\n",
      "619 1\n",
      "1010 3\n",
      "1444 1\n",
      "131 2\n",
      "1240 4\n",
      "669 3\n",
      "262 3\n",
      "497 2\n",
      "515 2\n",
      "342 9\n",
      "2198 1\n",
      "705 2\n",
      "879 1\n",
      "1619 1\n",
      "547 1\n",
      "731 1\n",
      "901 2\n",
      "514 1\n",
      "771 3\n",
      "21 3\n",
      "1060 1\n",
      "965 1\n",
      "2683 1\n",
      "1152 1\n",
      "5550 1\n",
      "179 5\n",
      "522 1\n",
      "4660 1\n",
      "910 1\n",
      "552 2\n",
      "639 2\n",
      "506 2\n",
      "1025 1\n",
      "546 3\n",
      "419 1\n",
      "920 1\n",
      "609 3\n",
      "1080 1\n",
      "1354 1\n",
      "940 3\n",
      "5560 1\n",
      "990 2\n",
      "7530 1\n",
      "615 1\n",
      "491 1\n",
      "3344 1\n",
      "2310 1\n",
      "1420 2\n",
      "753 2\n",
      "624 2\n",
      "2890 1\n",
      "2416 1\n",
      "687 1\n",
      "827 2\n",
      "694 1\n",
      "713 1\n",
      "343 1\n",
      "1054 1\n",
      "282 1\n",
      "702 1\n",
      "2345 1\n",
      "934 1\n",
      "279 2\n",
      "436 2\n",
      "1470 1\n",
      "379 2\n",
      "426 2\n",
      "2531 1\n",
      "2230 1\n",
      "836 1\n",
      "3241 1\n",
      "451 1\n",
      "31 1\n",
      "1201 1\n",
      "349 3\n",
      "637 1\n",
      "1362 1\n",
      "1625 2\n",
      "724 1\n",
      "3750 1\n",
      "403 3\n",
      "508 2\n",
      "2685 1\n",
      "363 1\n",
      "1021 1\n",
      "1580 1\n",
      "366 2\n",
      "914 1\n",
      "1555 1\n",
      "2248 1\n",
      "612 1\n",
      "1410 1\n",
      "889 2\n",
      "864 1\n",
      "3455 1\n",
      "166 1\n",
      "439 1\n",
      "422 1\n",
      "1742 1\n",
      "704 1\n",
      "443 2\n",
      "733 1\n",
      "4788 1\n",
      "1523 1\n",
      "507 1\n",
      "2880 2\n",
      "3411 1\n",
      "1203 1\n",
      "617 1\n",
      "1893 1\n",
      "91 2\n",
      "2238 1\n",
      "378 3\n",
      "316 1\n",
      "614 1\n",
      "1032 1\n",
      "3568 1\n",
      "2992 1\n",
      "955 1\n",
      "534 2\n",
      "781 3\n",
      "1439 1\n",
      "6302 1\n",
      "763 1\n",
      "2905 1\n",
      "975 1\n",
      "553 1\n",
      "1260 2\n",
      "2518 1\n",
      "688 1\n",
      "593 1\n",
      "3031 1\n",
      "311 1\n",
      "1183 1\n",
      "1144 1\n",
      "1221 1\n",
      "895 1\n",
      "11463 1\n",
      "1005 1\n",
      "2250 3\n",
      "526 1\n",
      "1545 1\n",
      "644 1\n",
      "1340 1\n",
      "3620 1\n",
      "1164 1\n",
      "605 1\n",
      "3850 1\n",
      "774 1\n",
      "3589 1\n",
      "936 2\n",
      "866 1\n",
      "697 1\n",
      "2750 1\n",
      "693 1\n",
      "795 1\n",
      "607 1\n",
      "1325 1\n",
      "2145 1\n",
      "1363 1\n",
      "417 1\n",
      "681 1\n",
      "765 1\n",
      "582 1\n",
      "985 1\n",
      "1290 1\n",
      "197 1\n",
      "2461 1\n",
      "398 1\n",
      "912 1\n",
      "775 1\n",
      "682 1\n",
      "1244 1\n",
      "1090 1\n",
      "2010 1\n",
      "3250 1\n",
      "613 1\n",
      "429 1\n",
      "862 1\n",
      "1422 1\n",
      "2570 1\n",
      "4208 1\n",
      "387 1\n",
      "8200 1\n",
      "2430 1\n",
      "2569 1\n",
      "541 1\n",
      "845 1\n",
      "976 1\n",
      "788 1\n",
      "lessthan50:  29\n",
      "lessthan30:  40\n",
      "lessthan20:  100\n",
      "lessthan10:  796\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "analyze_in_detail_unique_values_for_column(df_training_data, \"population\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyze_in_detail_unique_values_for_column(df_training_data, \"management\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyze_in_detail_unique_values_for_column(df_training_data, \"management_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyze_in_detail_unique_values_for_column(df_training_data, \"extraction_type_class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df_training_labels['id']\n",
    "df_training_data, df_topredict_data = dates(df_training_data, df_topredict_data)\n",
    "df_training_data, df_topredict_data = dates2(df_training_data, df_topredict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute missing construction year with median construction year\n",
    "df_training_data = impute_missing_construction_year(df_training_data)\n",
    "df_topredict_data = impute_missing_construction_year(df_topredict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the fields public_meeting and permit are boolean, but there are many missing values (3334 in public_meeting and 3056 in permit)\n",
    "# impute these missing values with FALSE\n",
    "df_training_data = impute_missing_booleans(df_training_data, \"public_meeting\")\n",
    "df_topredict_data = impute_missing_booleans(df_topredict_data, \"public_meeting\")\n",
    "\n",
    "df_training_data = impute_missing_booleans(df_training_data, \"permit\")\n",
    "df_topredict_data = impute_missing_booleans(df_topredict_data, \"permit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fill in the nulls for ['longitude', 'latitude', 'gps_height', 'population'] by using means from \n",
    "['subvillage', 'district_code', 'basin'], and lastly the overall mean\n",
    "\"\"\"\n",
    "df_training_data, df_topredict_data = locs(df_training_data, df_topredict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_training_data['population'] = np.log(df_training_data['population'])\n",
    "df_topredict_data['population'] = np.log(df_topredict_data['population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop unwanted columns \n",
    "columns_to_drop = ['id','amount_tsh',  'num_private', 'region', 'quantity', 'quality_group', 'source_type', 'payment', \n",
    "'waterpoint_type_group', 'extraction_type_group', 'recorded_by']\n",
    "df_training_data = drop_columns(df_training_data, columns_to_drop)\n",
    "df_topredict_data = drop_columns(df_topredict_data, columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_training_data, df_topredict_data = small_n2(df_training_data, df_topredict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_training_data, df_topredict_data = lda(df_training_data, df_topredict_data, df_training_labels, cols = ['gps_height', 'latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encode the columns that have string values\n",
    "df_training_data,df_topredict_data = one_hot_encode(df_training_data, df_topredict_data)\n",
    "#df_topredict_data = one_hot_encode1(df_topredict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df_training_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='gini', min_samples_split=6, n_estimators=1000, max_features='auto',\n",
    "     oob_score=True, random_state=1, n_jobs=-1)\n",
    "rf.fit(df_training_data, df_training_labels.values.ravel())\n",
    "print (\"%.4f\" % rf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = rf.predict(df_topredict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['id','status_group']\n",
    "df_submission = pd.DataFrame(columns=columns)\n",
    "to_predict_features=pd.read_csv('TestSetValues.csv',parse_dates=True)\n",
    "to_predict_features = to_predict_features.reset_index(drop=True)\n",
    "df_predictions = df_predictions.reset_index(drop=True)\n",
    "df_submission = df_submission.reset_index(drop=True)\n",
    "df_submission['id'] = to_predict_features['id']\n",
    "df_submission['status_group'] = df_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv(\"submission_csv_29_3_1.csv\", sep=\",\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "X_train, X_test, y_train, y_test = \n",
    "    train_test_split(df_training_data, df_training_labels_num, test_size = 0.25, random_state = 42)\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "features_to_consider =\n",
    "    ['amount_tsh', 'gps_height', 'longitude', 'latitude', 'region_code', 'district_code', 'population', 'construction_year']\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "#def run_random_forest_predictor(X_train1, y_train1, X_test1, y_test1, features_to_consider):\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "df1 = X_train[features_to_consider]\n",
    "rf.fit(df1, y_train)\n",
    "predictions = rf.predict(X_test[features_to_consider])\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - y_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\"\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
