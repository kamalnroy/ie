{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Include required libs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # function to load training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to load training and testing data\n",
    "def load_train_and_test_data():\n",
    "    train_features=pd.read_csv('TrainingSetValues.csv',parse_dates=True)\n",
    "    train_labels=pd.read_csv('TrainingSetLabels.csv')\n",
    "    to_predict_features=pd.read_csv('TestSetValues.csv',parse_dates=True)\n",
    "    \n",
    "    # merge training features and labels\n",
    "    #training_data = pd.merge(train_features, train_labels, how='inner', on=['id'])\n",
    "    \n",
    "    return train_features, train_labels, to_predict_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# impute median values for 0 amount_tsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute median values for 0 amount_tsh\n",
    "def impute_missing_amount_tsh(df):\n",
    "    df.amount_tsh[df.amount_tsh <= 0] = np.median(df.amount_tsh[df.amount_tsh > 0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# impute median values for 0 gps height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute median values for 0 gps height\n",
    "def impute_missing_gps_height(df):\n",
    "    df.gps_height[df.gps_height <= 0] = np.median(df.gps_height[df.gps_height > 0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# impute median values for 0 population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute median values for 0 population\n",
    "def impute_missing_population(df):\n",
    "    df.population[df.population <= 0] = np.median(df.population[df.population > 0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transform population into categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform population into categories\n",
    "def label_population(row):\n",
    "    if row['population'] <=0:\n",
    "        return 'NA'\n",
    "    elif row['population'] >= 1 and row['population'] <= 40:\n",
    "        return 'A'\n",
    "    elif row['population'] >= 41 and row['population'] <= 67:\n",
    "        return 'B'\n",
    "    elif row['population'] >= 68 and row['population'] <= 99:\n",
    "        return 'C'\n",
    "    elif row['population'] >= 100 and row['population'] <= 131:\n",
    "        return 'D'\n",
    "    elif row['population'] >= 132 and row['population'] <= 175:\n",
    "        return 'E'\n",
    "    elif row['population'] >= 176 and row['population'] <= 219:\n",
    "        return 'F'\n",
    "    elif row['population'] >= 220 and row['population'] <= 259:\n",
    "        return 'G'\n",
    "    elif row['population'] >= 260 and row['population'] <= 349:\n",
    "        return 'H'\n",
    "    elif row['population'] >= 350 and row['population'] <= 448:\n",
    "        return 'I'\n",
    "    elif row['population'] >= 449 and row['population'] <= 598:\n",
    "        return 'J'\n",
    "    elif row['population'] >= 599 and row['population'] <= 1290:\n",
    "        return 'K'\n",
    "    elif row['population'] >= 1291:\n",
    "        return 'L'\n",
    "\n",
    "def transform_population_into_categories(df):\n",
    "    df['population_cat'] = df.apply(label_population, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# impute median values for construction year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute median values for construction year\n",
    "def impute_missing_construction_year(df):\n",
    "    df.construction_year[df.construction_year <= 0] = np.median(df.construction_year[df.construction_year > 0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# impute missing booleans with false and convert each value to float or integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute missing booleans with false and convert each value to float or integer\n",
    "def impute_missing_booleans(df, colname):\n",
    "    df[colname].fillna(False, inplace = True)\n",
    "    df[colname] = df[colname].apply(lambda x: float(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Since random forest doesnt work on datetime, we will break them down to month and year.\n",
    "# But, also if we simply convert month into numerical values, it doesnt work well because there may be big distance between Jan and December and also between 1970 to  2010, to take an example.\n",
    "# So its better to one hot encode them after transforming the date to month and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since random forest doesnt work on datetime, we will break them down to month and year.\n",
    "# But, also if we simply convert month into numerical values, it doesnt work well because \n",
    "# there may be big distance between Jan and December and also between 1970 to  2010, to take an example.\n",
    "# So its better to one hot encode them after transforming the date to month and year\n",
    "def transform_date_recorded_to_month_and_year(df):\n",
    "    df['date_recorded'] = pd.to_datetime(df['date_recorded'])\n",
    "    df['year_recorded'] = df['date_recorded'].apply(lambda x: x.year)\n",
    "    df['month_recorded'] = df['date_recorded'].apply(lambda x: x.month)\n",
    "    df['date_recorded'] = (pd.to_datetime(df['date_recorded'])).apply(lambda x: x.toordinal())\n",
    "    return df\n",
    "\n",
    "# One Hot encode year and month recorded (first convert the month and year to string beafore OHEing)\n",
    "# Also delete the original ones\n",
    "def ohe_month_and_year_recorded(df_train, df_test):\n",
    "    df_train = transform_date_recorded_to_month_and_year(df_train)\n",
    "    df_test = transform_date_recorded_to_month_and_year(df_test)\n",
    "    for col in ['month_recorded', 'year_recorded']:\n",
    "        df_train[col] = df_train[col].apply(lambda x: str(x))\n",
    "        df_test[col] = df_test[col].apply(lambda x: str(x))\n",
    "        ohe_cols_postfix = [col + '_' + i for i in df_train[col].unique() if i in df_test[col].unique()]\n",
    "        df_train = pd.concat((df_train, pd.get_dummies(df_train[col], prefix = col)[ohe_cols_postfix]), axis = 1)\n",
    "        df_test = pd.concat((df_test, pd.get_dummies(df_test[col], prefix = col)[ohe_cols_postfix]), axis = 1)\n",
    "        del df_test[col]\n",
    "        del df_train[col]\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if latitude and/or lngitude is set to 0 or 1, it means that its a junk value. The latitude and longitude of Tanzania don't fall in this range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if latitude and/or lngitude is set to 0 or 1, it means that its a junk\n",
    "# value. The latitude and longitude of Tanzania don't fall in this range\n",
    "def cleanup_missing_latitude_and_longitude(df):\n",
    "    df.loc[df.longitude == 0, 'latitude'] = 0\n",
    "    df.loc[df.latitude == 1, 'longitude'] = 0\n",
    "    \n",
    "    df.loc[df.latitude == 0, 'longitude'] = 0\n",
    "    df.loc[df.latitude == 1, 'longitude'] = 0\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper function to drop columns from a dataframe df is the dataframe from where we need to drop a column cols_to_drop is the list of column names that have to be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to drop columns from a dataframe\n",
    "# df is the dataframe from where we need to drop a column\n",
    "# cols_to_drop is the list of column names that have to be dropped\n",
    "def drop_columns(df, cols_to_drop):\n",
    "    for col in cols_to_drop:\n",
    "        del df[col]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def locs1(X_train, X_test):\n",
    "#    \"\"\"\n",
    "#    fill in the nulls for ['longitude', 'latitude', 'gps_height', 'population'] by using means from \n",
    "#    ['subvillage', 'district_code', 'basin'], and lastly the overall mean\n",
    "#    \"\"\"\n",
    "#    trans = ['longitude', 'latitude', 'gps_height', 'population']\n",
    "#    for i in [X_train, X_test]:\n",
    "#        i.loc[i.longitude == 0, 'latitude'] = 0\n",
    "#    for z in trans:\n",
    "#        for i in [X_train, X_test]:\n",
    "#            i[z].replace(0., np.NaN, inplace = True)\n",
    "#            i[z].replace(1., np.NaN, inplace = True)\n",
    "#        \n",
    "#        #for j in ['subvillage', 'district_code', 'basin']:\n",
    "#        for j in ['subvillage']:\n",
    "#            X_train['mean'] = X_train.groupby([j])[z].transform('mean')\n",
    "#            X_train[z] = X_train[z].fillna(X_train['mean'])\n",
    "#            o = X_train.groupby([j])[z].mean()\n",
    "#            fill = pd.merge(X_test, pd.DataFrame(o), left_on=[j], right_index=True, how='left').iloc[:,-1]\n",
    "#            X_test[z] = X_test[z].fillna(fill)\n",
    "#        \n",
    "#        X_train[z] = X_train[z].fillna(X_train[z].mean())\n",
    "#        X_test[z] = X_test[z].fillna(X_train[z].mean())\n",
    "#        del X_train['mean']\n",
    "#    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def locs(X_train, X_test):\n",
    "#    \"\"\"\n",
    "#    fill in the nulls for ['longitude', 'latitude', 'gps_height', 'population'] by using means from \n",
    "#    ['subvillage', 'district_code', 'basin'], and lastly the overall mean\n",
    "#    \"\"\"\n",
    "#    for i in [X_train, X_test]:\n",
    "#        i.loc[i.longitude == 0, 'latitude'] = 0\n",
    "#    for i in [X_train, X_test]:\n",
    "#        i.loc[i.latitude == 1, 'longitude'] = 0\n",
    "#\n",
    "#    for i in [X_train, X_test]:\n",
    "#        i.loc[i.latitude == 0, 'longitude'] = 0\n",
    "#    for i in [X_train, X_test]:\n",
    "#        i.loc[i.latitude == 1, 'longitude'] = 0\n",
    "#        \n",
    "#    trans = ['longitude', 'latitude', 'gps_height', 'population']\n",
    "#    for z in trans:\n",
    "#        for i in [X_train, X_test]:\n",
    "#            i[z].replace(0., np.NaN, inplace = True)\n",
    "#            i[z].replace(1., np.NaN, inplace = True)\n",
    "#        \n",
    "#        #for j in ['subvillage', 'district_code', 'basin']:\n",
    "#        for j in ['subvillage']:\n",
    "#            X_train['mean'] = X_train.groupby([j])[z].transform('mean')\n",
    "#            X_train[z] = X_train[z].fillna(X_train['mean'])\n",
    "#            o = X_train.groupby([j])[z].mean()\n",
    "#            fill = pd.merge(X_test, pd.DataFrame(o), left_on=[j], right_index=True, how='left').iloc[:,-1]\n",
    "#            X_test[z] = X_test[z].fillna(fill)\n",
    "#        \n",
    "#        X_train[z] = X_train[z].fillna(X_train[z].mean())\n",
    "#        X_test[z] = X_test[z].fillna(X_train[z].mean())\n",
    "#        del X_train['mean']\n",
    "#    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def locs2(df_train, df_test):\n",
    "#    \"\"\"\n",
    "#    fill in the nulls for ['longitude', 'latitude', 'gps_height', 'population'] by using means from \n",
    "#    ['subvillage', 'district_code', 'basin'], and lastly the overall mean\n",
    "##    \"\"\"\n",
    "##    for i in [df_train, df_test]:\n",
    "##        i.loc[i.longitude == 0, 'latitude'] = 0\n",
    "##    for i in [df_train, df_test]:\n",
    "##        i.loc[i.latitude == 1, 'longitude'] = 0\n",
    "##\n",
    "##    for i in [df_train, df_test]:\n",
    "##        i.loc[i.latitude == 0, 'longitude'] = 0\n",
    "##    for i in [df_train, df_test]:\n",
    "##        i.loc[i.latitude == 1, 'longitude'] = 0\n",
    "#        \n",
    "#    trans = ['longitude', 'latitude', 'gps_height', 'population']\n",
    "#    for z in trans:\n",
    "#        for i in [df_train, df_test]:\n",
    "#            i[z].replace(0., np.NaN, inplace = True)\n",
    "#            i[z].replace(1., np.NaN, inplace = True)\n",
    "#        \n",
    "#        #for j in ['subvillage', 'district_code', 'basin']:\n",
    "#        for j in ['subvillage']:\n",
    "#            df_train['mean'] = df_train.groupby([j])[z].transform('mean')\n",
    "#            df_train[z] = df_train[z].fillna(df_train['mean'])\n",
    "#            o = df_train.groupby([j])[z].mean()\n",
    "#            fill = pd.merge(df_test, pd.DataFrame(o), left_on=[j], right_index=True, how='left').iloc[:,-1]\n",
    "#            df_test[z] = df_test[z].fillna(fill)\n",
    "#        \n",
    "#        df_train[z] = df_train[z].fillna(df_train[z].mean())\n",
    "#        df_test[z] = df_test[z].fillna(df_train[z].mean())\n",
    "#        del df_train['mean']\n",
    "#    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This function imputes missing/junk/illegal values in numerical columns with the mean of the respective fields grouped by subvillage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function imputes missing/junk/illegal values in numerical columns with the mean of the respective \n",
    "# fields grouped by subvillage.\n",
    "def fill_col_vals_with_col_mean_grp_by_subvilage(df_train, df_test, columns):\n",
    "    for column in columns:\n",
    "        df_train[column].replace(0., np.NaN, inplace = True)\n",
    "        df_train[column].replace(1., np.NaN, inplace = True)\n",
    "        df_test[column].replace(0., np.NaN, inplace = True)\n",
    "        df_test[column].replace(1., np.NaN, inplace = True)\n",
    "        \n",
    "        df_train['mean'] = df_train.groupby(['subvillage'])[column].transform('mean')\n",
    "        df_train[column] = df_train[column].fillna(df_train['mean'])\n",
    "        o = df_train.groupby(['subvillage'])[column].mean()\n",
    "        fill = pd.merge(df_test, pd.DataFrame(o), left_on=['subvillage'], right_index=True, how='left').iloc[:,-1]\n",
    "        df_test[column] = df_test[column].fillna(fill)\n",
    "        \n",
    "        df_train[column] = df_train[column].fillna(df_train[column].mean())\n",
    "        df_test[column] = df_test[column].fillna(df_train[column].mean())\n",
    "        del df_train['mean']\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are many columns that have many different values. Since our motive is to one hot encode the categorical columns, we need to reduce the no. of categories for each column. For this purpose we are putting together all the values that have counts less than 100 as \"other\" category for each column that contains string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There are many columns that have many different values. Since our motive is to one hot encode the categorical columns,\n",
    "# we need to reduce the no. of categories for each column. For this purpose we are putting together all the values that have \n",
    "# counts less than 100 as \"other\" category for each column that contains string values\n",
    "def shrink_categories_for_columns(X_train, X_test):\n",
    "    cols = [i for i in X_train.columns if type(X_train[i].iloc[0]) == str]\n",
    "    #print(cols)\n",
    "    #['funder', 'installer', 'wpt_name', 'basin', 'scheme_management', 'extraction_type', \n",
    "    # 'extraction_type_class', 'management', 'management_group', 'payment_type', 'water_quality', \n",
    "    #'quantity_group', 'source', 'source_class', 'waterpoint_type']\n",
    "    X_train[cols] = X_train[cols].where(X_train[cols].apply(lambda x: x.map(x.value_counts())) > 100, \"other\")\n",
    "    for column in cols:\n",
    "        for i in X_test[column].unique():\n",
    "            if i not in X_train[column].unique():\n",
    "                X_test[column].replace(i, 'other', inplace=True)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This function makes use of LDA to reduce the no. of dimensions. We will apply these on population, gps_height, latitude longitude because these have many different values and hence they are perfect candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function makes use of LDA to reduce the no. of dimensions. We will apply these on population, gps_height, latitude\n",
    "# longitude because these have many different values and hence they are perfect candidates\n",
    "def reduce_dimensions_using_lda(X_train, X_test, y_train, cols=['population', 'gps_height', 'latitude', 'longitude']):\n",
    "    sc = StandardScaler()\n",
    "    X_train_std = sc.fit_transform(X_train[cols])\n",
    "    X_test_std = sc.transform(X_test[cols])\n",
    "    lda = LDA(n_components=None)\n",
    "    X_train_lda = lda.fit_transform(X_train_std, y_train.values.ravel())\n",
    "    X_test_lda = lda.transform(X_test_std)\n",
    "    X_train = pd.concat((pd.DataFrame(X_train_lda), X_train), axis=1)\n",
    "    X_test = pd.concat((pd.DataFrame(X_test_lda), X_test), axis=1)\n",
    "    for i in cols:\n",
    "        del X_train[i]\n",
    "        del X_test[i]\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function for dummy-encoding i.e. one-hot-encoding of categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for dummy-encoding i.e. ne-hot-encoding of categorical columns\n",
    "def one_hot_encode(df_train, df_test):\n",
    "    columns = [i for i in df_train.columns if type(df_train[i].iloc[0]) == str]\n",
    "    for column in columns:\n",
    "        df_train[column].fillna('NULL', inplace = True)\n",
    "        ohe_cols = [column+'_'+i for i in df_train[column].unique() if i in df_test[column].unique()]\n",
    "        df_train = pd.concat((df_train, pd.get_dummies(df_train[column], prefix = column)[ohe_cols]), axis = 1)\n",
    "        df_test = pd.concat((df_test, pd.get_dummies(df_test[column], prefix = column)[ohe_cols]), axis = 1)\n",
    "        del df_train[column]\n",
    "        del df_test[column]\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick and dirty data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A quick and dirty data analysis\n",
    "def do_some_data_analysis(training_data, training_labels):\n",
    "    # find unique labels\n",
    "    unique_labels = training_labels['status_group'].unique()\n",
    "    unique_labels.sort()\n",
    "    print(\"Unique labels are:\", unique_labels)\n",
    "    \n",
    "    # find the count of each unique labels\n",
    "    unique_labels_cnt = []\n",
    "    cnt = training_labels[training_labels['status_group']=='functional']['status_group'].count()\n",
    "    unique_labels_cnt.append(cnt)\n",
    "    cnt = training_labels[training_labels['status_group']=='functional needs repair']['status_group'].count()\n",
    "    unique_labels_cnt.append(cnt)\n",
    "    cnt = training_labels[training_labels['status_group']=='non functional']['status_group'].count()\n",
    "    unique_labels_cnt.append(cnt)\n",
    "    #unique_labels_count.\n",
    "    print(\"count of each type of pump(functional/functional-needs-repair/non functional)\")\n",
    "    print(unique_labels_cnt)\n",
    "    y_pos = np.arange(len(unique_labels))\n",
    "    plt.bar(y_pos, unique_labels_cnt, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, unique_labels)\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of status of pumps') \n",
    "    plt.show()\n",
    "    \n",
    "    # year-wise distribution of pumps in different conditions\n",
    "#   training_data.construction_year=pd.to_numeric(training_data.construction_year)\n",
    "#   training_data.loc[training_data.construction_year <= 0, training_data.columns=='construction_year'] = 1950\n",
    "#   hist1=training_data[training_data.status_group == 'functional'].construction_year\n",
    "#   hist2=training_data[training_data.status_group == 'functional needs repair'].construction_year\n",
    "#   hist3=training_data[training_data.status_group == 'non functional'].construction_year\n",
    "#   n,b,p=plt.hist([hist1, hist2, hist3], stacked=True,range=[1950,2010])\n",
    "#   plt.legend(['functional', 'functional needs repair','non functional'],loc=0)\n",
    "#   plt.text(1952, 15000,'NO DATA',fontsize=20,rotation=90,color='white')\n",
    "#   plt.xlabel('Construction Year', fontsize=18)\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function for column values analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function for column values analysis\n",
    "def analyze_unique_values_for_column(df, colname):\n",
    "    unique_col_vals = df[colname].unique()\n",
    "    tmp_str = \"Unique \" + colname + \"s:\"\n",
    "    print(\"****************************\")\n",
    "    print(tmp_str, unique_col_vals.size)\n",
    "    print(\"****************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function for column values analysis. This function helped us in detailed analysis for the purpose of feature engineering and helped us in finding out what function to keep/ what too drop/ what values to put under one single category and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function for column values analysis. This function helped us in detailed analysis for the purpose of feature\n",
    "# engineering and helped us in finding out what function to keep/ what too drop/ what values to put under one single category\n",
    "# and so on.\n",
    "def analyze_in_detail_unique_values_for_column(df, colname):\n",
    "    unique_col_vals = df[colname].unique()\n",
    "    tmp_str = \"Unique \" + colname + \"s:\"\n",
    "    print(\"****************************\")\n",
    "    print(tmp_str, unique_col_vals.size)\n",
    "    print(\"****************************\")\n",
    "    lessthan10 = 0\n",
    "    lessthan20 = 0\n",
    "    lessthan30 = 0\n",
    "    lessthan50 = 0\n",
    "    lessthan100 = 0\n",
    "    for val in unique_col_vals:\n",
    "        cnt = df[df[colname] == val][colname].count()\n",
    "        print(val, cnt) # uncomment this line if you want to see the count of each colname-value\n",
    "        if(cnt < 10):\n",
    "            lessthan10 +=1     \n",
    "            print(val, cnt)\n",
    "        elif(cnt < 20):\n",
    "            lessthan20 +=1\n",
    "        elif(cnt < 30):\n",
    "            lessthan30 +=1\n",
    "        elif(cnt < 50):\n",
    "            lessthan50 +=1\n",
    "\n",
    "    print(\"lessthan50: \", lessthan50 )\n",
    "    print(\"lessthan30: \", lessthan30 )\n",
    "    print(\"lessthan20: \", lessthan20 )\n",
    "    print(\"lessthan10: \", lessthan10 )\n",
    "    print(\"****************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the traiing and testing(to be predicted) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-5618f9677d07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load the training and testing(to be predcicted) data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_training_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_training_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_topredict_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_train_and_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-60a765f3408d>\u001b[0m in \u001b[0;36mload_train_and_test_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# function to load training and testing data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_train_and_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TrainingSetValues.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtrain_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TrainingSetLabels.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mto_predict_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TestSetValues.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# load the training and testing(to be predcicted) data\n",
    "df_training_data, df_training_labels, df_topredict_data = load_train_and_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some quick analysis about the no. of functional/needs-repair/non-functional pumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some quick analysis about the no. of functional/needs-repair/non-functional pumps\n",
    "do_some_data_analysis(df_training_data, df_training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep a copy of the \"to be predicted data\" from where we can extract the id for the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep a copy of the \"to be predicted data\" from where we can extract the id for the submission file\n",
    "df_to_predict_data1 = df_topredict_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief Stats of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*****************************************\\nBrief Stats of each column\\n*****************************************\")\n",
    "print(df_training_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting number of nonzeros in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting number of nonzeros in each column\n",
    "print(\"\\n*****************************************\\nnumber of nonzeros in each column\\n*****************************************\")\n",
    "print(df_training_data.astype(bool).sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting no. of nulls in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting no. of nulls in each column\n",
    "print(\"\\n*****************************************\\nno. of nulls in each column\\n*****************************************\")\n",
    "print(df_training_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to briefly analyze each column\n",
    "def briefly_analyze_each_column(df_training_data):\n",
    "    analyze_unique_values_for_column(df_training_data, \"funder\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"installer\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"wpt_name\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"basin\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"subvillage\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"region\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"region_code\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"district_code\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"lga\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"ward\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"recorded_by\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"scheme_management\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"scheme_name\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"extraction_type\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"extraction_type_group\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"extraction_type_class\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"management\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"management_group\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"management_group\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"payment\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"payment_type\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"management_group\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"water_quality\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"quality_group\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"quantity\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"quantity_group\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"source\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"source_type\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"source_class\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"source_class\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"waterpoint_type\")\n",
    "    analyze_unique_values_for_column(df_training_data, \"waterpoint_type_group\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# uncomment the following function if we need to analyze the columns in brief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#briefly_analyze_each_column(df_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The next few function calls help us do a detailed analysis of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_in_detail_unique_values_for_column(df_training_data, \"funder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyze_in_detail_unique_values_for_column(df_training_data, \"installer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyze_in_detail_unique_values_for_column(df_training_data, \"wpt_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_in_detail_unique_values_for_column(df_training_data, \"management\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_in_detail_unique_values_for_column(df_training_data, \"management_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_in_detail_unique_values_for_column(df_training_data, \"extraction_type_class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We dont need the id field in trainign labels, delete this\n",
    "del df_training_labels['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break down the date_recorded into month and year and one hot encode them\n",
    "# Since random forest doesnt work on datetime, we will break them down to month and year.\n",
    "# But, also if we simply convert month into numerical values, it doesnt work well because there may be big distance between Jan and December and also between 1970 to  2010, to take an example.\n",
    "# So its better to one hot encode them after transforming the date to month and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Break down the date_recorded into month and year and one hot encode them\n",
    "# Since random forest doesnt work on datetime, we will break them down to month and year.\n",
    "# But, also if we simply convert month into numerical values, it doesnt work well because \n",
    "# there may be big distance between Jan and December and also between 1970 to  2010, to take an example.\n",
    "# So its better to one hot encode them after transforming the date to month and year\n",
    "df_training_data, df_topredict_data = ohe_month_and_year_recorded(df_training_data, df_topredict_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# impute missing construction year with median construction year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing construction year with median construction year\n",
    "df_training_data = impute_missing_construction_year(df_training_data)\n",
    "df_topredict_data = impute_missing_construction_year(df_topredict_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the fields public_meeting and permit are boolean, but there are many missing values (3334 in public_meeting and 3056 in permit) \n",
    "# impute these missing values with FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the fields public_meeting and permit are boolean, but there are many missing values \n",
    "# (3334 in public_meeting and 3056 in permit)\n",
    "# impute these missing values with FALSE\n",
    "df_training_data = impute_missing_booleans(df_training_data, \"public_meeting\")\n",
    "df_topredict_data = impute_missing_booleans(df_topredict_data, \"public_meeting\")\n",
    "\n",
    "df_training_data = impute_missing_booleans(df_training_data, \"permit\")\n",
    "df_topredict_data = impute_missing_booleans(df_topredict_data, \"permit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if latitude and/or lngitude is set to 0 or 1, it means that its a junk value. The latitude and longitude of Tanzania don't fall in this range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if latitude and/or lngitude is set to 0 or 1, it means that its a junk\n",
    "# value. The latitude and longitude of Tanzania don't fall in this range\n",
    "df_training_data = cleanup_missing_latitude_and_longitude(df_training_data)\n",
    "df_topredict_data = cleanup_missing_latitude_and_longitude(df_topredict_data)\n",
    "\n",
    "# fill in the nulls for ['longitude', 'latitude', 'gps_height'] by using the mean of the respective columns\n",
    "# grouped by subvillage; subvillage has the highest granularity compared to region_code, district_code, ward, basin etc.\n",
    "# We could also use the overalll mean, but more granularity is better\n",
    "location_columns_to_clean = ['longitude', 'latitude', 'gps_height']\n",
    "df_training_data, df_topredict_data = fill_col_vals_with_col_mean_grp_by_subvilage(df_training_data, df_topredict_data, location_columns_to_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if population field contains 0 or 1, it indiactes some junk value\n",
    "# fill these with median values for those subvillages and after that log-transform them. However, after log transformation, it was observed that there was no improvement in accuracy, but there was no harm either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location_columns_to_clean = ['population']\n",
    "df_training_data, df_topredict_data = fill_col_vals_with_col_mean_grp_by_subvilage(df_training_data, df_topredict_data, location_columns_to_clean)\n",
    "df_training_data['population'] = np.log(df_training_data['population'])\n",
    "df_topredict_data['population'] = np.log(df_topredict_data['population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drop unwanted columns \n",
    "\n",
    "# We will drop the following columns because of the reasons mentioned below:\n",
    "# 1. id - Not a feature \n",
    "# 2. amount_tsh - \n",
    "# 3. num_private - too many different values(approx 58000), so holds no significance\n",
    "# 4. region - almost perfect correaltion with region_code\n",
    "# 5. quantity - very strong correlation with quantity_group\n",
    "# 6. quality_group - very strong correlation with water_quality\n",
    "# 7. source_type - very strong correlation with source\n",
    "# 8. water_point_group - very strong correlation with water_point_type\n",
    "# 9. payment - very strong correlation with payment_type\n",
    "# 10. extraction_type_group - strong correlation with extraction_type\n",
    "# 11. recorded_by - same values in all the rows, so its not a discriminant\n",
    "# 12. subvillage/district_code/lga/ward - all these denote region, as such we can drop these. region is already being represented \n",
    "#     by lat/long and also by region_code\n",
    "# 13. scheme_name - 2697 different values and 28166 empty values; so this field is almost useless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop unwanted columns \n",
    "columns_to_drop = ['id','amount_tsh', 'num_private', 'region', 'quantity', 'quality_group', 'source_type', 'payment', \n",
    "'waterpoint_type_group', 'extraction_type_group', 'recorded_by', 'subvillage', 'district_code', 'lga', 'ward', 'scheme_name']\n",
    "df_training_data = drop_columns(df_training_data, columns_to_drop)\n",
    "df_topredict_data = drop_columns(df_topredict_data, columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There are many columns that have many different values. Since our motive is to one hot encode the categorical columns,\n",
    "# we need to reduce the no. of categories for each column. For this purpose we are putting together all the values that have \n",
    "# counts less than 100 as \"other\" category for each column that contains string values\n",
    "df_training_data, df_topredict_data = shrink_categories_for_columns(df_training_data, df_topredict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make use of LDA to reduce the no. of dimensions\n",
    "df_training_data, df_topredict_data = reduce_dimensions_using_lda(\n",
    "    df_training_data, df_topredict_data, df_training_labels, cols = ['gps_height', 'latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encode the columns that have categorical values\n",
    "df_training_data,df_topredict_data = one_hot_encode(df_training_data, df_topredict_data)\n",
    "#df_topredict_data = one_hot_encode1(df_topredict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the final no. of columns on which RandomForestClassifier is going to run; just for diagnostic purposes\n",
    "print(len(df_training_data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following 2 functions help us in hyperparameter tuning of RandomForestCalssifier fucntion(the variables such as) n_estimators, max_features, max_depth, criterion(gini/entropy), min_samples_split\n",
    "# Using the output of this function we tuned the respective parameters for RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following 2 functions help us in hyperparameter tuning of RandomForestCalssifier fucntion(the variables such as)\n",
    "# n_estimators, max_features, max_depth, criterion(gini/entropy), min_samples_split\n",
    "# Using the output of this function we tuned the respective parameters for RandomForestClassifier\n",
    "\n",
    "# function to evaluate the performance of a model\n",
    "def evaluate_model_performance(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# This function is used for finding the best suitable value for hyperparameter tuning.\n",
    "def find_best_values_for_hyperparameters(X_train, y_train):\n",
    "    rf = RandomForestClassifier(criterion='gini', max_features='auto', min_samples_split=6, \n",
    "                                oob_score=True, random_state=1, n_jobs=-1)\n",
    "\n",
    "    #param_grid = {\"n_estimators\" : [500, 750, 1000], \"min_samples_split\" : [4, 6, 8]}\n",
    "\n",
    "    param_grid = { 'n_estimators': [200, 500, 750, 1000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth' : [4,5,6,7,8],\n",
    "        'criterion' :['gini', 'entropy'], 'min_samples_split' : [4, 6, 8] }\n",
    "\n",
    "    gs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "\n",
    "    gs = gs.fit(X_train, y_train)\n",
    "    print(gs.best_score_)\n",
    "    print(gs.best_params_)\n",
    "    print(gs.grid_scores_)\n",
    "    grid_accuracy = evaluate(best_grid, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_training_data, df_training_labels, test_size = 0.25, random_state = 42)\n",
    "## Create random forest classifier instance\n",
    "## Train and Test dataset size details\n",
    "print (\"X_train Shape :: \", X_train.shape)\n",
    "print (\"y_train Shape :: \", y_train.shape)\n",
    "print (\"X_test Shape :: \", X_test.shape)\n",
    "print (\"y_test Shape :: \", y_test.shape)\n",
    "\n",
    "# Uncomment this function for finding the best values for hyper-parameters\n",
    "#find_best_values_for_hyperparameters(X_train, y_train)\n",
    "\n",
    "rf = RandomForestClassifier(criterion='gini', min_samples_split=6, n_estimators=1000, max_features='auto', \n",
    "                            oob_score=True, random_state=1, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Train Accuracy :: \", accuracy_score(y_train, rf.predict(X_train)))\n",
    "print (\"Test Accuracy  :: \", accuracy_score(y_test, predictions))\n",
    "print (\"Confusion matrix \", confusion_matrix(y_test, predictions))\n",
    "\n",
    "predictions = rf.predict(df_topredict_data)\n",
    "df_predictions = pd.DataFrame(predictions)\n",
    "\n",
    "# Output the predictions into a csv file\n",
    "columns = ['id','status_group']\n",
    "df_submission = pd.DataFrame(columns=columns)\n",
    "df_to_predict_data1 = df_to_predict_data1.reset_index(drop=True)\n",
    "df_predictions = df_predictions.reset_index(drop=True)\n",
    "df_submission = df_submission.reset_index(drop=True)\n",
    "df_submission['id'] = df_to_predict_data1['id']\n",
    "df_submission['status_group'] = df_predictions[0]\n",
    "df_submission.to_csv(\"submission_ab_kn_on_split_data.csv\", sep=\",\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find_best_values_for_hyperparameters(df_training_data, df_training_labels.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the random forest classifier with the whole of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the random forest classifier with the whole of training data\n",
    "rf = RandomForestClassifier(criterion='gini', min_samples_split=6, n_estimators=1000, max_features='auto',\n",
    "     oob_score=True, random_state=1, n_jobs=-1)\n",
    "rf.fit(df_training_data, df_training_labels.values.ravel())\n",
    "\n",
    "# The accuracy score on training data\n",
    "print (\"%.4f\" % rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the values for which we don't have the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict the values for which we don't have the labels\n",
    "predictions = rf.predict(df_topredict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the list of predicted values into dataframe\n",
    "df_predictions = pd.DataFrame(predictions)\n",
    "df_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output the predictions into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output the predictions into a csv file\n",
    "columns = ['id','status_group']\n",
    "df_submission = pd.DataFrame(columns=columns)\n",
    "#to_predict_features=pd.read_csv('TestSetValues.csv',parse_dates=True)\n",
    "df_to_predict_data1 = df_to_predict_data1.reset_index(drop=True)\n",
    "df_predictions = df_predictions.reset_index(drop=True)\n",
    "df_submission = df_submission.reset_index(drop=True)\n",
    "df_submission['id'] = df_to_predict_data1['id']\n",
    "df_submission['status_group'] = df_predictions[0]\n",
    "df_submission.to_csv(\"submission_ab_kn.csv\", sep=\",\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_submission.shape)\n",
    "print(df_submission.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert string labels to numerics\n",
    "#label_map = {\"functional\": 1, \"functional needs repair\": 2, \"non functional\": 3}\n",
    "#df_training_data['status_group_num']= df_training_data['status_group'].map(label_map).astype(int)\n",
    "\n",
    "# do sanity check\n",
    "#df_training_data[['id', 'amount_tsh', 'status_group', 'status_group_num']].head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the training labels into a df\n",
    "#df_training_labels_str = df_training_data['status_group']\n",
    "#df_training_labels_num = np.array(df_training_data['status_group_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop the training labels from the training set\n",
    "#df_training_data= df_training_data.drop('status_group', axis = 1)\n",
    "#df_training_data= df_training_data.drop('status_group_num', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def one_hot_encode(X_train, X_test):\n",
    "#    columns = [i for i in X_train.columns if type(X_train[i].iloc[0]) == str]\n",
    "#    for column in columns:\n",
    "#        X_train[column].fillna('NULL', inplace = True)\n",
    "#        good_cols = [column+'_'+i for i in X_train[column].unique() if i in X_test[column].unique()]\n",
    "#        X_train = pd.concat((X_train, pd.get_dummies(X_train[column], prefix = column)[good_cols]), axis = 1)\n",
    "#        X_test = pd.concat((X_test, pd.get_dummies(X_test[column], prefix = column)[good_cols]), axis = 1)\n",
    "#        del X_train[column]\n",
    "#        del X_test[column]\n",
    "#    return X_train, X_test\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute missing population \n",
    "#df_training_data = impute_missing_population1(df_training_data)\n",
    "#df_topredict_data = impute_missing_population1(df_topredict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#analyze_in_detail_unique_values_for_column(df_training_data, 'population_cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\"\"\"\n",
    "#X_train, X_test, y_train, y_test = \n",
    "#    train_test_split(df_training_data, df_training_labels_num, test_size = 0.25, random_state = 42)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\"\"\"\n",
    "#features_to_consider =\n",
    "#    ['amount_tsh', 'gps_height', 'longitude', 'latitude', 'region_code', 'district_code', 'population', 'construction_year']\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\"\"\"\n",
    "##def run_random_forest_predictor(X_train1, y_train1, X_test1, y_test1, features_to_consider):\n",
    "#rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "## Train the model on training data\n",
    "#df1 = X_train[features_to_consider]\n",
    "#rf.fit(df1, y_train)\n",
    "#predictions = rf.predict(X_test[features_to_consider])\n",
    "## Calculate the absolute errors\n",
    "#errors = abs(predictions - y_test)\n",
    "## Print out the mean absolute error (mae)\n",
    "#print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
